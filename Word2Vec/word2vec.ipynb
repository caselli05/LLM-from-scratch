{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2e3de4",
   "metadata": {},
   "source": [
    "# Hand coded Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccac6f",
   "metadata": {},
   "source": [
    "1. Take a fake problem\n",
    "2. Solve it using neural network\n",
    "3. As a side effect, you get word embeddings\n",
    "\n",
    "Our fake problem: try to fill in a missing word in a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8ea5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dda6e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch is running on cuda\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    context_window = 5\n",
    "    count_words = 0\n",
    "\n",
    "    num_epochs = 20\n",
    "    batch_size = 128\n",
    "    embedding_dim = 100\n",
    "    lr=0.001\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Pytorch is running on {DEVICE}\")\n",
    "\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a3c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\pc-de-\n",
      "[nltk_data]     caselli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5495b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 57340 sentences from the Brown Corpus.\n"
     ]
    }
   ],
   "source": [
    "sentences = brown.sents()\n",
    "print(f\"Loaded {len(sentences)} sentences from the Brown Corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c86c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [\" \".join(s).lower() for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2efca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'[^\\W\\d_]+|[0-9]+'\n",
    "final_str_set = set()\n",
    "\n",
    "for text in all_texts:\n",
    "    # re.UNICODE is good practice\n",
    "    tokens = re.findall(pattern, text, re.UNICODE) \n",
    "    final_str_set.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "168b0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.count_words = len(final_str_set)\n",
    "word_to_int = {w: i for i, w in enumerate(final_str_set)}\n",
    "int_to_word = {i: w for w, i in word_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad5c5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([18321, 36068, 14995, 6263, 27484], 22991),\n",
       " ([22991, 36068, 14995, 6263, 27484, 28784], 18321),\n",
       " ([22991, 18321, 14995, 6263, 27484, 28784, 19156], 36068),\n",
       " ([22991, 18321, 36068, 6263, 27484, 28784, 19156], 14995),\n",
       " ([22991, 18321, 36068, 14995, 27484, 28784, 19156], 6263),\n",
       " ([22991, 18321, 36068, 14995, 6263, 28784, 19156], 27484),\n",
       " ([18321, 36068, 14995, 6263, 27484, 19156], 28784),\n",
       " ([36068, 14995, 6263, 27484, 28784], 19156)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_cbow_training_data(texts: list, word_to_int: dict):\n",
    "    pattern = r'[^\\W\\d_]+|[0-9]+'\n",
    "    \n",
    "    all_training_pairs = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(pattern, text, re.UNICODE) \n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        token_count = len(tokens)\n",
    "\n",
    "        for i in range(token_count):\n",
    "            center_word = tokens[i]\n",
    "            center_word_index = word_to_int.get(center_word) \n",
    "\n",
    "            if center_word_index is None:\n",
    "                continue\n",
    "\n",
    "            context_indices = []\n",
    "            \n",
    "            start_idx = max(0, i - cfg.context_window)\n",
    "            end_idx = min(token_count, i + 1 + cfg.context_window)\n",
    "\n",
    "            for j in range(start_idx, end_idx):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                context_word = tokens[j]\n",
    "                context_word_index = word_to_int.get(context_word)\n",
    "                \n",
    "                if context_word_index is not None:\n",
    "                    context_indices.append(context_word_index)\n",
    "            \n",
    "            if not context_indices:\n",
    "                continue\n",
    "            \n",
    "            all_training_pairs.append((context_indices, center_word_index))\n",
    "            \n",
    "    return all_training_pairs\n",
    "\n",
    "generate_cbow_training_data([\"I try and avoid this sort of conflict\"], word_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bf830d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positional_training_data(texts: list, word_to_int: dict):\n",
    "    pattern = r'[^\\W\\d_]+|[0-9]+'\n",
    "    \n",
    "    all_training_pairs = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = text.lower()\n",
    "        tokens = re.findall(pattern, text, re.UNICODE) \n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "        \n",
    "        token_count = len(tokens)\n",
    "\n",
    "        for i in range(token_count):\n",
    "            center_word = tokens[i]\n",
    "            center_word_index = word_to_int.get(center_word) \n",
    "\n",
    "            if center_word_index is None:\n",
    "                continue\n",
    "\n",
    "            context_positions = {}\n",
    "            \n",
    "            start_idx = max(0, i - cfg.context_window)\n",
    "            end_idx = min(token_count, i + 1 + cfg.context_window)\n",
    "\n",
    "            for j in range(start_idx, end_idx):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                    \n",
    "                context_word = tokens[j]\n",
    "                context_word_index = word_to_int.get(context_word)\n",
    "                \n",
    "                if context_word_index is not None:\n",
    "                    position = j - i\n",
    "                    \n",
    "                    context_positions.setdefault(context_word_index, []).append(position)\n",
    "            \n",
    "            if not context_positions:\n",
    "                continue\n",
    "                \n",
    "            word_emb_vector = np.zeros(shape=(cfg.count_words,))\n",
    "            \n",
    "            for word_index, positions_list in context_positions.items():\n",
    "                avg_position = np.mean(positions_list)\n",
    "                word_emb_vector[word_index] = avg_position\n",
    "            \n",
    "            all_training_pairs.append((word_emb_vector, center_word_index))\n",
    "            \n",
    "    return all_training_pairs\n",
    "t = generate_positional_training_data([\"I try and avoid and sort of conflict\"], word_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de9ed442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, training_data):\n",
    "        self.data = training_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        return torch.tensor(context, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "    \n",
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int):\n",
    "        super(CBOWModel, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_indices: torch.Tensor):\n",
    "        context_vectors = self.embeddings(context_indices)\n",
    "        \n",
    "        avg_context_vector = torch.mean(context_vectors, dim=1)\n",
    "        logits = self.output_layer(avg_context_vector)\n",
    "        return logits\n",
    "\n",
    "def collate_cbow(batch):\n",
    "    context_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    for context, target in batch:\n",
    "        context_list.append(context)\n",
    "        target_list.append(target)\n",
    "\n",
    "    padded_contexts = pad_sequence(context_list, batch_first=True, padding_value=0)\n",
    "    \n",
    "    stacked_targets = torch.stack(target_list)\n",
    "    \n",
    "    return padded_contexts, stacked_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82c3acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training ---\n",
      "Epoch 1/128, Loss: 7.424872215427421\n",
      "Epoch 2/128, Loss: 6.728880291415159\n",
      "Epoch 3/128, Loss: 6.437106705279015\n",
      "Epoch 4/128, Loss: 6.2266344074805975\n",
      "Epoch 5/128, Loss: 6.057589807583627\n",
      "Epoch 6/128, Loss: 5.914442331573535\n",
      "Epoch 7/128, Loss: 5.7885090966881565\n",
      "Epoch 8/128, Loss: 5.67693282597365\n",
      "Epoch 9/128, Loss: 5.57589150845591\n",
      "Epoch 10/128, Loss: 5.482726123335341\n",
      "Epoch 11/128, Loss: 5.39740704279116\n",
      "Epoch 12/128, Loss: 5.317301862658074\n",
      "Epoch 13/128, Loss: 5.242506398022825\n",
      "Epoch 14/128, Loss: 5.17200976911456\n",
      "Epoch 15/128, Loss: 5.104766934785191\n",
      "Epoch 16/128, Loss: 5.040821721461649\n",
      "Epoch 17/128, Loss: 4.980457327174479\n",
      "Epoch 18/128, Loss: 4.922334843749924\n",
      "Epoch 19/128, Loss: 4.866926189722462\n",
      "Epoch 20/128, Loss: 4.81305114264767\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "source": [
    "training_data = generate_cbow_training_data(all_texts, word_to_int)\n",
    "\n",
    "dataset = CBOWDataset(training_data)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_cbow\n",
    ")\n",
    "\n",
    "model = CBOWModel(cfg.count_words, cfg.embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "model.to(cfg.DEVICE)\n",
    "model.train()\n",
    "\n",
    "print(\"--- Starting Training ---\")\n",
    "for epoch in range(cfg.num_epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for context_batch, target_batch in data_loader:\n",
    "        context_batch = context_batch.to(cfg.DEVICE)\n",
    "        target_batch = target_batch.to(cfg.DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(context_batch)\n",
    "        loss = cfg.loss_function(logits, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{cfg.num_epochs}, Loss: {total_loss / len(data_loader)}\")\n",
    "print(\"--- Training Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c05888e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of our final embedding matrix: torch.Size([42325, 100])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "word_embeddings = model.embeddings.weight.data.cpu()\n",
    "\n",
    "print(f\"\\nShape of our final embedding matrix: {word_embeddings.shape}\")\n",
    "torch.save(word_embeddings, \"my_word_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01396b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.8574e-01, -3.2374e-02, -7.4229e-01,  ...,  6.1075e-01,\n",
       "          2.2968e-01,  1.5072e+00],\n",
       "        [ 2.1158e+00, -1.8626e-01,  1.0257e+00,  ...,  1.5958e+00,\n",
       "         -1.1144e-01, -6.1884e-01],\n",
       "        ...,\n",
       "        [ 6.9596e-01,  3.9360e-02,  1.8186e+00,  ..., -3.1483e-03,\n",
       "          1.5269e+00,  7.6351e-01],\n",
       "        [ 3.8152e+00,  1.5229e+00,  1.2885e+00,  ..., -2.0685e-01,\n",
       "         -7.1479e-01,  1.0372e+00],\n",
       "        [-8.8064e-01,  8.2757e-01,  6.3314e-01,  ...,  5.4394e-01,\n",
       "         -1.1798e+00,  7.5773e-01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed5174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analogy Test 1 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Similarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Analogy Test 1 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m get_analogy(\u001b[33m\"\u001b[39m\u001b[33mking\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwoman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mword_embeddings\u001b[49m, cfg)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Analogy Test 2 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m get_analogy(\u001b[33m\"\u001b[39m\u001b[33mqueen\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwoman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mman\u001b[39m\u001b[33m\"\u001b[39m, word_embeddings, cfg)\n",
      "\u001b[31mNameError\u001b[39m: name 'word_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_analogy(word_a: str, word_b: str, word_c: str, embeddings: torch.Tensor, cfg: Config):\n",
    "    w2i = word_to_int\n",
    "    i2w = int_to_word\n",
    "    \n",
    "    for word in [word_a, word_b, word_c]:\n",
    "        if word not in w2i:\n",
    "            print(f\"Error: Word '{word}' is not in the vocabulary.\")\n",
    "            return\n",
    "            \n",
    "    vec_a = embeddings[w2i[word_a]]\n",
    "    vec_b = embeddings[w2i[word_b]]\n",
    "    vec_c = embeddings[w2i[word_c]]\n",
    "    \n",
    "    target_vec = vec_a - vec_b + vec_c\n",
    "    \n",
    "    all_similarities = F.cosine_similarity(target_vec.unsqueeze(0), embeddings)\n",
    "    \n",
    "    for word in [word_a, word_b, word_c]:\n",
    "        all_similarities[w2i[word]] = -float('inf')\n",
    "        \n",
    "    top_5_scores, top_5_indices = torch.topk(all_similarities, 5)\n",
    "    \n",
    "    print(f\"Analogy: {word_a} - {word_b} + {word_c} = ?\\n\")\n",
    "    print(\"Top 5 results:\")\n",
    "    for i in range(5):\n",
    "        word = i2w[top_5_indices[i].item()]\n",
    "        score = top_5_scores[i].item()\n",
    "        print(f\"  {i+1}. {word} (Similarity: {score:.4f})\")\n",
    "        \n",
    "print(\"\\n--- Analogy Test 1 ---\")\n",
    "get_analogy(\"king\", \"man\", \"woman\", word_embeddings, cfg)\n",
    "\n",
    "print(\"\\n--- Analogy Test 2 ---\")\n",
    "get_analogy(\"queen\", \"woman\", \"man\", word_embeddings, cfg)\n",
    "\n",
    "print(\"\\n--- Analogy Test 3 ---\")\n",
    "get_analogy(\"image\", \"images\", \"cell\", word_embeddings, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1e16035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retirements',\n",
       " 'observation',\n",
       " 'uneconomic',\n",
       " 'committees',\n",
       " 'collecting',\n",
       " 'cropping',\n",
       " 'swelling',\n",
       " 'zu',\n",
       " 'guilty',\n",
       " 'reservoirs',\n",
       " 'sufferers',\n",
       " 'ym',\n",
       " 'quaver',\n",
       " 'woodshed',\n",
       " 'hurtling',\n",
       " 'mandamus',\n",
       " 'bechhofer',\n",
       " 'predictably',\n",
       " 'ziraldo',\n",
       " 'flamboyant',\n",
       " 'de',\n",
       " 'provdied',\n",
       " 'stern',\n",
       " 'jilted',\n",
       " 'revolutionaries',\n",
       " 'geary',\n",
       " 'rifled',\n",
       " 'triumphant',\n",
       " 'impoundments',\n",
       " 'sameness',\n",
       " 'bacteria',\n",
       " 'rendering',\n",
       " 'steinkerque',\n",
       " 'resorcinol',\n",
       " 'keyboarding',\n",
       " 'bruises',\n",
       " 'stubbs',\n",
       " 'pizzicato',\n",
       " 'tardiness',\n",
       " 'hammarskjold',\n",
       " 'ra',\n",
       " 'pondering',\n",
       " 'chum',\n",
       " 'fantasist',\n",
       " 'knee',\n",
       " 'python',\n",
       " 'dine',\n",
       " 'diamond',\n",
       " 'stanchest',\n",
       " 'troupes',\n",
       " 'qui',\n",
       " 'devotional',\n",
       " 'mastery',\n",
       " 'patents',\n",
       " 'domesday',\n",
       " 'vallee',\n",
       " 'english',\n",
       " 'publique',\n",
       " 'photocathode',\n",
       " 'affix',\n",
       " 'imperturbable',\n",
       " 'aerobic',\n",
       " 'omnipotence',\n",
       " 'archaeology',\n",
       " 'drains',\n",
       " 'dingo',\n",
       " 'influx',\n",
       " 'identifies',\n",
       " 'nominee',\n",
       " 'unbroken',\n",
       " 'manley',\n",
       " 'ultrasonically',\n",
       " 'rates',\n",
       " 'contemplating',\n",
       " 'clan',\n",
       " 'noncommittal',\n",
       " 'doctrinally',\n",
       " 'enamel',\n",
       " 'tape',\n",
       " 'fumble',\n",
       " 'smile',\n",
       " 'lay',\n",
       " 'designs',\n",
       " 'miuchi',\n",
       " 'predestined',\n",
       " 'mingle',\n",
       " 'slid',\n",
       " 'voltages',\n",
       " 'poisoned',\n",
       " 'contingent',\n",
       " 'empting',\n",
       " 'paschal',\n",
       " 'session',\n",
       " 'initiates',\n",
       " 'boniface',\n",
       " 'indicted',\n",
       " 'pairs',\n",
       " 'thutmose',\n",
       " 'draftee',\n",
       " 'cashews',\n",
       " 'echelon',\n",
       " 'confucianism',\n",
       " 'brutal',\n",
       " 'collapsible',\n",
       " 'rapunzel',\n",
       " 'ajar',\n",
       " 'determination',\n",
       " 'morose',\n",
       " 'fifth',\n",
       " 'reversal',\n",
       " 'allegorical',\n",
       " 'squeaked',\n",
       " 'startlingly',\n",
       " 'fraternisation',\n",
       " 'surely',\n",
       " 'cabinetmakers',\n",
       " 'pleasant',\n",
       " 'heated',\n",
       " 'giacometti',\n",
       " 'drones',\n",
       " 'treasonable',\n",
       " 'isotopic',\n",
       " 'lapels',\n",
       " 'confessionals',\n",
       " 'supplements',\n",
       " 'immensely',\n",
       " 'optimizing',\n",
       " 'dyke',\n",
       " 'shin',\n",
       " 'suffragettes',\n",
       " 'gascony',\n",
       " 'exaggerate',\n",
       " 'massachusetts',\n",
       " 'hybrid',\n",
       " 'bellyfull',\n",
       " 'prizes',\n",
       " 'enumeration',\n",
       " 'haughtiness',\n",
       " 'jabbed',\n",
       " 'sobbingly',\n",
       " 'foggy',\n",
       " 'gret',\n",
       " 'beaver',\n",
       " 'ccc',\n",
       " 'coffers',\n",
       " 'valuation',\n",
       " 'barbour',\n",
       " 'photomicrography',\n",
       " 'katherine',\n",
       " 'institutes',\n",
       " 'patil',\n",
       " 'whiteface',\n",
       " 'altitude',\n",
       " 'ductwork',\n",
       " 'sucker',\n",
       " 'hawkinses',\n",
       " 'unrelenting',\n",
       " 'made',\n",
       " 'cordier',\n",
       " 'facsimile',\n",
       " 'secesh',\n",
       " 'lateran',\n",
       " 'construing',\n",
       " 'flapper',\n",
       " '203',\n",
       " 'beaming',\n",
       " 'trays',\n",
       " 'transmittable',\n",
       " 'releasing',\n",
       " 'advent',\n",
       " 'bo',\n",
       " 'pinkish',\n",
       " 'bravest',\n",
       " 'aristocrats',\n",
       " 'fergeson',\n",
       " 'distinguish',\n",
       " 'interne',\n",
       " 'forborne',\n",
       " 'untimely',\n",
       " 'tenancy',\n",
       " 'biconcave',\n",
       " 'hoc',\n",
       " 'gabler',\n",
       " 'asset',\n",
       " 'teetotaler',\n",
       " 'laundering',\n",
       " 'morphology',\n",
       " 'instigator',\n",
       " 'believer',\n",
       " 'bonaventure',\n",
       " 'inlaid',\n",
       " 'taboos',\n",
       " 'abeyance',\n",
       " 'abstracting',\n",
       " '650',\n",
       " 'pantomimic',\n",
       " 'dam',\n",
       " 'surreptitiously',\n",
       " 'merz',\n",
       " 'ruysch',\n",
       " 'profanity',\n",
       " 'humilation',\n",
       " 'ruckus',\n",
       " 'creedal',\n",
       " 'glorified',\n",
       " 'microcurie',\n",
       " 'reassuring',\n",
       " 'sundry',\n",
       " 'boatmen',\n",
       " 'decompose',\n",
       " 'chewing',\n",
       " 'waged',\n",
       " 'suzerainty',\n",
       " 'yearn',\n",
       " 'haggardly',\n",
       " 'bernard',\n",
       " 'spectra',\n",
       " 'novo',\n",
       " 'abusive',\n",
       " 'burrows',\n",
       " 'permeate',\n",
       " 'lawman',\n",
       " 'adhered',\n",
       " 'connection',\n",
       " 'rightist',\n",
       " 'pickfair',\n",
       " 'pray',\n",
       " 'mann',\n",
       " 'owes',\n",
       " 'lunatic',\n",
       " 'israelites',\n",
       " 'culturally',\n",
       " 'perils',\n",
       " 'buffetings',\n",
       " 'spill',\n",
       " 'readjustment',\n",
       " 'ap',\n",
       " 'downtown',\n",
       " 'bazaar',\n",
       " 'candidly',\n",
       " 'javert',\n",
       " 'my',\n",
       " 'sonambula',\n",
       " 'instinctive',\n",
       " 'landslide',\n",
       " 'sus',\n",
       " 'movement',\n",
       " 'budlong',\n",
       " 'majors',\n",
       " 'masted',\n",
       " 'admissions',\n",
       " 'leak',\n",
       " 'weaker',\n",
       " 'zapala',\n",
       " 'gapt',\n",
       " 'luck',\n",
       " 'splotches',\n",
       " 'loudspeakers',\n",
       " 'seeking',\n",
       " 'whipsnade',\n",
       " 'wustman',\n",
       " 'pigs',\n",
       " 'architectural',\n",
       " 'terrorists',\n",
       " 'biologic',\n",
       " 'fail',\n",
       " 'harnick',\n",
       " 'stroll',\n",
       " 'unconvincing',\n",
       " 'inappropriateness',\n",
       " 'buell',\n",
       " 'flu',\n",
       " 'simms',\n",
       " 'incapable',\n",
       " 'pilgrims',\n",
       " 'tannin',\n",
       " 'nuclide',\n",
       " 'westerner',\n",
       " 'release',\n",
       " 'poignantly',\n",
       " 'multivalent',\n",
       " 'interlibrary',\n",
       " 'closets',\n",
       " 'sides',\n",
       " 'indian',\n",
       " 'ostracized',\n",
       " 'delivering',\n",
       " 'ditches',\n",
       " 'contained',\n",
       " 'linear',\n",
       " 'stampeded',\n",
       " 'facilities',\n",
       " 'rimbaud',\n",
       " '508',\n",
       " 'refreshed',\n",
       " 'magnificent',\n",
       " 'partitions',\n",
       " 'asymptotically',\n",
       " '185',\n",
       " 'shunning',\n",
       " 'evanston',\n",
       " 'prove',\n",
       " 'investigator',\n",
       " 'commercials',\n",
       " 'confesses',\n",
       " 'dynamited',\n",
       " 'bows',\n",
       " 'modular',\n",
       " 'exclusively',\n",
       " 'twirling',\n",
       " 'sniffle',\n",
       " 'dew',\n",
       " 'peale',\n",
       " 'plasma',\n",
       " 'autopsy',\n",
       " 'shots',\n",
       " 'conjoined',\n",
       " '1951',\n",
       " 'trujillos',\n",
       " 'cumbersome',\n",
       " 'peccavi',\n",
       " 'entrust',\n",
       " 'redistricting',\n",
       " 'initiated',\n",
       " 'slavish',\n",
       " 'ounce',\n",
       " 'hotly',\n",
       " 'authenticate',\n",
       " 'cleaved',\n",
       " 'abstinence',\n",
       " 'humanist',\n",
       " 'ijal',\n",
       " 'gorgeous',\n",
       " 'inextricable',\n",
       " 'diffraction',\n",
       " 'legatee',\n",
       " 'murky',\n",
       " 'legitimately',\n",
       " 'stands',\n",
       " 'calibrations',\n",
       " 'obeyed',\n",
       " 'aerosolized',\n",
       " 'mccay',\n",
       " 'armisteads',\n",
       " 'condemnatory',\n",
       " 'walkers',\n",
       " 'sound',\n",
       " 'ominous',\n",
       " 'mold',\n",
       " 'crabs',\n",
       " 'bade',\n",
       " 'loused',\n",
       " 'englishman',\n",
       " 'titans',\n",
       " 'recreational',\n",
       " 'eagerness',\n",
       " 'strands',\n",
       " 'discipline',\n",
       " 'guerrillas',\n",
       " 'simplicitude',\n",
       " 'sana',\n",
       " 'clenches',\n",
       " 'doolin',\n",
       " 'chocks',\n",
       " 'unreasoning',\n",
       " 'julep',\n",
       " 'keepers',\n",
       " 'ml',\n",
       " 'print',\n",
       " 'longstanding',\n",
       " 'engh',\n",
       " 'cavin',\n",
       " 'magi',\n",
       " 'flag',\n",
       " 'relaxing',\n",
       " 'imprisons',\n",
       " 'wanting',\n",
       " 'journalism',\n",
       " 'rudolph',\n",
       " 'fundamentalism',\n",
       " 'toch',\n",
       " 'taney',\n",
       " 'identifications',\n",
       " 'honeymooners',\n",
       " 'carloads',\n",
       " 'resolved',\n",
       " 'treat',\n",
       " 'registrations',\n",
       " 'joblot',\n",
       " 'immunization',\n",
       " 'skit',\n",
       " 'breakdowns',\n",
       " 'prematurely',\n",
       " 'burnished',\n",
       " 'conversions',\n",
       " 'vaughn',\n",
       " 'crossed',\n",
       " 'digital',\n",
       " 'servitors',\n",
       " 'regretfully',\n",
       " 'paucity',\n",
       " 'sherry',\n",
       " 'quintet',\n",
       " 'leeds',\n",
       " 'fellows',\n",
       " 'avaricious',\n",
       " 'asteroid',\n",
       " 'furiously',\n",
       " 'epoxy',\n",
       " 'lalaurie',\n",
       " 'debating',\n",
       " 'polyunsaturated',\n",
       " 'impetus',\n",
       " 'arrests',\n",
       " 'covet',\n",
       " 'angelina',\n",
       " 'harsher',\n",
       " 'herb',\n",
       " 'barefoot',\n",
       " 'mausoleum',\n",
       " 'crevices',\n",
       " 'shopworn',\n",
       " 'blackboard',\n",
       " 'bobby',\n",
       " 'ching',\n",
       " 'lowly',\n",
       " 'hyperplasia',\n",
       " 'crispin',\n",
       " 'haney',\n",
       " 'favorer',\n",
       " 'charcoal',\n",
       " 'upperclassmen',\n",
       " 'superfluous',\n",
       " 'masseur',\n",
       " 'soft',\n",
       " 'wilson',\n",
       " 'outlets',\n",
       " 'collected',\n",
       " 'occasions',\n",
       " 'harpy',\n",
       " 'kelley',\n",
       " 'bellwethers',\n",
       " 'staple',\n",
       " 'biscuits',\n",
       " 'disapprobation',\n",
       " 'hollyhock',\n",
       " 'meddling',\n",
       " 'framework',\n",
       " 'individually',\n",
       " 'huston',\n",
       " 'binge',\n",
       " 'inclusions',\n",
       " 'terrace',\n",
       " 'bigoted',\n",
       " 'retriever',\n",
       " 'substrates',\n",
       " 'humaine',\n",
       " 'sadism',\n",
       " 'winter',\n",
       " 'belmont',\n",
       " 'morrison',\n",
       " 'gilmore',\n",
       " 'castigation',\n",
       " 'filched',\n",
       " 'wholes',\n",
       " 'hard',\n",
       " 'whipsawed',\n",
       " 'betrayer',\n",
       " 'intentioned',\n",
       " 'picks',\n",
       " 'rung',\n",
       " 'loathed',\n",
       " 'synthesis',\n",
       " 'gauer',\n",
       " 'tappan',\n",
       " 'averaged',\n",
       " 'froze',\n",
       " 'connell',\n",
       " 'theirs',\n",
       " 'nest',\n",
       " 'pavement',\n",
       " 'ceasing',\n",
       " 'allay',\n",
       " 'fer',\n",
       " 'heading',\n",
       " 'gumming',\n",
       " 'instructs',\n",
       " 'pantomimed',\n",
       " 'exhibitions',\n",
       " 'howry',\n",
       " 'wyatt',\n",
       " 'subjectivists',\n",
       " 'unbridled',\n",
       " 'appeasing',\n",
       " 'straddled',\n",
       " 'braun',\n",
       " 'whereof',\n",
       " 'scraggly',\n",
       " 'reminisces',\n",
       " 'friars',\n",
       " 'swiftest',\n",
       " 'easterners',\n",
       " 'clothed',\n",
       " 'lilly',\n",
       " 'signpost',\n",
       " 'bilingual',\n",
       " 'fret',\n",
       " 'pityingly',\n",
       " 'pricing',\n",
       " 'depicted',\n",
       " 'overdone',\n",
       " 'meadows',\n",
       " 'sickly',\n",
       " 'topmost',\n",
       " 'crochet',\n",
       " '566',\n",
       " 'goa',\n",
       " 'industry',\n",
       " 'fullness',\n",
       " 'recommence',\n",
       " 'tarry',\n",
       " 'butyrate',\n",
       " 'vacationers',\n",
       " 'zeal',\n",
       " 'terrible',\n",
       " 'carey',\n",
       " 'member',\n",
       " 'uppance',\n",
       " 'cult',\n",
       " 'polybutene',\n",
       " 'lyman',\n",
       " 'niche',\n",
       " 'wasting',\n",
       " 'waymouth',\n",
       " 'analogue',\n",
       " 'perpetuating',\n",
       " 'nennius',\n",
       " 'cambridgeport',\n",
       " 'svevo',\n",
       " 'arside',\n",
       " 'capitalize',\n",
       " 'peterson',\n",
       " 'brevet',\n",
       " 'reconsidered',\n",
       " 'mlle',\n",
       " 'thoroughness',\n",
       " 'description',\n",
       " 'indignation',\n",
       " 'instigate',\n",
       " 'stidger',\n",
       " 'twitched',\n",
       " 'gardenias',\n",
       " 'casuals',\n",
       " 'improvising',\n",
       " 'encircled',\n",
       " 'exceptionally',\n",
       " 'scientist',\n",
       " 'burrow',\n",
       " 'cavalrymen',\n",
       " 'ballyhoo',\n",
       " 'outfox',\n",
       " 'packaged',\n",
       " 'lately',\n",
       " 'ashikaga',\n",
       " 'jeweler',\n",
       " 'tests',\n",
       " 'engulfs',\n",
       " 'zeros',\n",
       " 'correlatively',\n",
       " 'prussian',\n",
       " 'creased',\n",
       " 'transgressed',\n",
       " 'alternating',\n",
       " 'femmes',\n",
       " 'cometh',\n",
       " 'judgeship',\n",
       " 'sacks',\n",
       " 'vented',\n",
       " 'where',\n",
       " 'unplumbed',\n",
       " 'weil',\n",
       " 'pickman',\n",
       " 'sprague',\n",
       " 'dimes',\n",
       " 'eleanor',\n",
       " 'boisterous',\n",
       " 'wrists',\n",
       " 'haruo',\n",
       " 'inverted',\n",
       " 'severna',\n",
       " 'lots',\n",
       " 'solved',\n",
       " '989',\n",
       " 'aggregations',\n",
       " 'veneer',\n",
       " 'demoted',\n",
       " 'kenneth',\n",
       " 'confide',\n",
       " 'metis',\n",
       " 'smoothing',\n",
       " 'model',\n",
       " 'leverkuhn',\n",
       " 'flannels',\n",
       " 'scarecrowish',\n",
       " 'fanned',\n",
       " 'tonally',\n",
       " 'undisclosed',\n",
       " 'rotenone',\n",
       " 'pinched',\n",
       " 'sneering',\n",
       " 'heed',\n",
       " 'parolees',\n",
       " 'flamboyantly',\n",
       " 'heaves',\n",
       " 'tem',\n",
       " 'biltmore',\n",
       " 'stalag',\n",
       " 'foundations',\n",
       " 'reveals',\n",
       " 'strutted',\n",
       " 'inquire',\n",
       " '1816',\n",
       " 'ginkgo',\n",
       " 'myself',\n",
       " 'comer',\n",
       " 'ouse',\n",
       " 'unreassuringly',\n",
       " 'wondered',\n",
       " 'hemorrhages',\n",
       " 'hastened',\n",
       " 'sham',\n",
       " 'contributing',\n",
       " 'prolusions',\n",
       " 'overture',\n",
       " 'status',\n",
       " 'repertoire',\n",
       " 'italo',\n",
       " 'typographic',\n",
       " 'presuppose',\n",
       " 'miliaris',\n",
       " 'emergent',\n",
       " 'zoned',\n",
       " 'alec',\n",
       " 'gargery',\n",
       " 'yanking',\n",
       " 'crusaders',\n",
       " 'alain',\n",
       " 'suit',\n",
       " 'empty',\n",
       " 'unborn',\n",
       " 'gristmill',\n",
       " 'surmise',\n",
       " 'generals',\n",
       " 'arabs',\n",
       " 'unsupportable',\n",
       " 'astronomical',\n",
       " 'layton',\n",
       " 'bottom',\n",
       " 'sheldon',\n",
       " 'diem',\n",
       " 'cotten',\n",
       " 'confiscated',\n",
       " 'cinch',\n",
       " 'ainu',\n",
       " 'cause',\n",
       " 'paradoxical',\n",
       " 'cleaned',\n",
       " 'spoken',\n",
       " 'dictators',\n",
       " 'skopas',\n",
       " 'represented',\n",
       " '1845',\n",
       " 'improving',\n",
       " 'fellow',\n",
       " 'smilin',\n",
       " 'lobl',\n",
       " 'enraged',\n",
       " 'zabel',\n",
       " 'freethinkers',\n",
       " 'probation',\n",
       " 'fairness',\n",
       " 'despise',\n",
       " 'simpliciter',\n",
       " 'dessert',\n",
       " 'collegiate',\n",
       " 'wrenching',\n",
       " 'freehand',\n",
       " 'hurriedly',\n",
       " 'humorists',\n",
       " 'deftness',\n",
       " 'pornographer',\n",
       " 'ladies',\n",
       " 'mai',\n",
       " 'personnel',\n",
       " 'craven',\n",
       " 'publication',\n",
       " 'provided',\n",
       " 'bowan',\n",
       " 'understanding',\n",
       " 'smarted',\n",
       " 'bonne',\n",
       " '550',\n",
       " 'cecilia',\n",
       " 'there',\n",
       " 'bystander',\n",
       " 'woodside',\n",
       " '792',\n",
       " 'ommission',\n",
       " 'garbage',\n",
       " 'sunshades',\n",
       " 'furbishing',\n",
       " 'foraging',\n",
       " 'iniquitous',\n",
       " 'groaned',\n",
       " 'triol',\n",
       " 'voluntarily',\n",
       " 'lions',\n",
       " 'uns',\n",
       " 'floater',\n",
       " 'forefeet',\n",
       " 'chronicles',\n",
       " 'tigard',\n",
       " 'yankeefication',\n",
       " 'scapegoat',\n",
       " 'whirlwind',\n",
       " 'pliable',\n",
       " 'elders',\n",
       " 'asses',\n",
       " 'towsley',\n",
       " 'schapiro',\n",
       " 'accords',\n",
       " 'campus',\n",
       " 'orchestre',\n",
       " 'misanthrope',\n",
       " 'twotiming',\n",
       " 'gregg',\n",
       " 'enzymes',\n",
       " 'centimeter',\n",
       " 'lublin',\n",
       " 'nasal',\n",
       " 'found',\n",
       " 'retied',\n",
       " 'emperor',\n",
       " 'structurally',\n",
       " 'petruchka',\n",
       " 'halcyon',\n",
       " 'governess',\n",
       " 'obsidian',\n",
       " 'broglie',\n",
       " 'cartridges',\n",
       " 'breton',\n",
       " 'pretended',\n",
       " 'semitropical',\n",
       " 'hershel',\n",
       " 'gus',\n",
       " 'yoneda',\n",
       " 'politico',\n",
       " 'cock',\n",
       " 'ancient',\n",
       " 'wrappin',\n",
       " 'eye',\n",
       " 'symbolically',\n",
       " 'slits',\n",
       " 'pfennig',\n",
       " 'assertion',\n",
       " 'nights',\n",
       " 'energizes',\n",
       " 'shipper',\n",
       " 'scottish',\n",
       " 'powdery',\n",
       " 'dependency',\n",
       " 'omega',\n",
       " 'biology',\n",
       " 'topographic',\n",
       " 'shrubs',\n",
       " 'gassings',\n",
       " 'litigation',\n",
       " 'berkeley',\n",
       " 'glomerular',\n",
       " 'widegrip',\n",
       " 'brigadier',\n",
       " 'enzo',\n",
       " 'unconditioned',\n",
       " 'christsake',\n",
       " 'closeups',\n",
       " 'gold',\n",
       " 'abridgment',\n",
       " 'mechanist',\n",
       " 'announcing',\n",
       " 'saturated',\n",
       " 'deceleration',\n",
       " 'marking',\n",
       " 'mauri',\n",
       " 'titles',\n",
       " 'splashed',\n",
       " 'yalagaloo',\n",
       " 'accessory',\n",
       " 'newspaper',\n",
       " 'no',\n",
       " 'aviation',\n",
       " 'bonnet',\n",
       " 'assessments',\n",
       " 'materialism',\n",
       " 'snatch',\n",
       " 'peculiarly',\n",
       " 'desperadoes',\n",
       " 'politically',\n",
       " 'mustard',\n",
       " 'administer',\n",
       " 'bracelet',\n",
       " 'buyin',\n",
       " 'ducts',\n",
       " 'elgin',\n",
       " 'respectful',\n",
       " 'verplanck',\n",
       " 'aorta',\n",
       " 'curtiss',\n",
       " 'agreeableness',\n",
       " 'delimits',\n",
       " 'brushes',\n",
       " 'atonement',\n",
       " 'reappraisals',\n",
       " 'microphoning',\n",
       " 'dignitaries',\n",
       " 'creative',\n",
       " 'uno',\n",
       " 'sethness',\n",
       " 'taras',\n",
       " 'emmett',\n",
       " 'jagged',\n",
       " 'spillane',\n",
       " 'paintings',\n",
       " 'strain',\n",
       " 'rap',\n",
       " 'three',\n",
       " 'guileless',\n",
       " 'canter',\n",
       " 'thinner',\n",
       " 'durin',\n",
       " 'officielle',\n",
       " 'boundless',\n",
       " 'strongest',\n",
       " 'wailing',\n",
       " 'zoology',\n",
       " 'hugo',\n",
       " 'wacker',\n",
       " 'translation',\n",
       " 'presentational',\n",
       " 'stairway',\n",
       " 'ferraro',\n",
       " 'courcy',\n",
       " 'indictments',\n",
       " 'newspapers',\n",
       " 'phosphorus',\n",
       " 'resurrecting',\n",
       " 'grumbling',\n",
       " '1592',\n",
       " 'strapped',\n",
       " 'menaced',\n",
       " 'accardo',\n",
       " 'fade',\n",
       " 'holden',\n",
       " 'handicap',\n",
       " 'gag',\n",
       " 'dorsey',\n",
       " 'mame',\n",
       " 'panoramas',\n",
       " 'streak',\n",
       " 'disrupted',\n",
       " '940',\n",
       " 'sorting',\n",
       " 'unhinged',\n",
       " 'sailorly',\n",
       " 'bungalow',\n",
       " 'ones',\n",
       " 'camilla',\n",
       " 'fanatical',\n",
       " 'fatalists',\n",
       " 'hothouse',\n",
       " 'intriguing',\n",
       " 'motional',\n",
       " 'gasse',\n",
       " 'typewriter',\n",
       " 'brutally',\n",
       " 'torquers',\n",
       " 'disarm',\n",
       " 'bernini',\n",
       " 'erroneous',\n",
       " 'neocortical',\n",
       " 'oppressive',\n",
       " 'lamming',\n",
       " 'jealousies',\n",
       " 'xreserve',\n",
       " 'beardown',\n",
       " 'emphasis',\n",
       " 'isolationism',\n",
       " 'kiss',\n",
       " 'veterinarians',\n",
       " 'laureate',\n",
       " 'foh',\n",
       " 'reveal',\n",
       " 'presidency',\n",
       " 'jets',\n",
       " 'eminently',\n",
       " 'moire',\n",
       " 'pastness',\n",
       " 'township',\n",
       " 'recent',\n",
       " 'fairways',\n",
       " 'venable',\n",
       " 'luftwaffe',\n",
       " 'headquarter',\n",
       " 'uplift',\n",
       " 'undrinkable',\n",
       " 'consultation',\n",
       " 'mclauchlin',\n",
       " 'experimenting',\n",
       " 'proportional',\n",
       " 'allergy',\n",
       " 'terg',\n",
       " 'sent',\n",
       " 'intervened',\n",
       " 'proliferation',\n",
       " '1880',\n",
       " 'stigmata',\n",
       " 'coasted',\n",
       " 'malady',\n",
       " 'szold',\n",
       " 'forgo',\n",
       " 'shuz',\n",
       " 'ascending',\n",
       " 'realest',\n",
       " 'dazzling',\n",
       " 'radiation',\n",
       " 'weinberg',\n",
       " 'lehner',\n",
       " 'handclasp',\n",
       " 'davits',\n",
       " '31978',\n",
       " 'harvie',\n",
       " 'incessantly',\n",
       " 'abstaining',\n",
       " 'disconcertingly',\n",
       " '900',\n",
       " 'shantung',\n",
       " 'hearings',\n",
       " 'garza',\n",
       " 'pound',\n",
       " 'psychiatry',\n",
       " 'ku',\n",
       " 'buchheister',\n",
       " 'sibling',\n",
       " 'coupal',\n",
       " 'hilton',\n",
       " 'gazette',\n",
       " 'larson',\n",
       " '1700',\n",
       " 'est',\n",
       " 'hardness',\n",
       " 'neveh',\n",
       " 'unquestionably',\n",
       " 'ekstrohm',\n",
       " 'silke',\n",
       " 'braved',\n",
       " 'hemispherical',\n",
       " 'workman',\n",
       " 'aback',\n",
       " 'creator',\n",
       " 'munger',\n",
       " 'stalemate',\n",
       " 'tardily',\n",
       " 'shoelace',\n",
       " 'orderliness',\n",
       " 'faintest',\n",
       " 'limits',\n",
       " 'contracted',\n",
       " 'outcome',\n",
       " 'mealynosed',\n",
       " 'physicochemical',\n",
       " 'biographical',\n",
       " 'cursory',\n",
       " 'starbird',\n",
       " 'said',\n",
       " 'combustion',\n",
       " 'fiddling',\n",
       " 'frowzy',\n",
       " 'derby',\n",
       " 'frankfurt',\n",
       " 'scope',\n",
       " 'foal',\n",
       " 'websterville',\n",
       " 'snodgrass',\n",
       " 'exodus',\n",
       " 'raiders',\n",
       " 'graying',\n",
       " 'bullfinch',\n",
       " 'headstand',\n",
       " 'foreman',\n",
       " 'stoopin',\n",
       " 'lipson',\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_str_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
